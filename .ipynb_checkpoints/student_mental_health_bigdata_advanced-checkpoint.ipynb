{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f73330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, OneHotEncoder, PCA\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator, BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "EXPORT_DIR = \"exports\"\n",
    "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
    "\n",
    "spark = SparkSession.builder.appName(\"StudentMentalHealthBigDataAdvanced\").getOrCreate()\n",
    "\n",
    "data_path = \"students_mental_health.csv\"\n",
    "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "df.printSchema()\n",
    "df.show(5)\n",
    "\n",
    "key_columns = ['Age', 'CGPA', 'Depression_Score', 'Anxiety_Score']\n",
    "df = df.na.drop(subset=key_columns)\n",
    "\n",
    "fillna_cols = [\n",
    "    'Gender', 'Sleep_Quality', 'Physical_Activity', 'Diet_Quality',\n",
    "    'Social_Support', 'Relationship_Status', 'Substance_Use',\n",
    "    'Counseling_Service_Use', 'Family_History', 'Chronic_Illness',\n",
    "    'Extracurricular_Involvement', 'Residence_Type'\n",
    "]\n",
    "for c in fillna_cols:\n",
    "    df = df.fillna({c: \"Unknown\"})\n",
    "\n",
    "categorical_cols = fillna_cols + ['Course']\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=c+\"_idx\", handleInvalid='keep') for c in categorical_cols]\n",
    "for indexer in indexers:\n",
    "    df = indexer.fit(df).transform(df)\n",
    "encoder = OneHotEncoder(inputCols=[c+\"_idx\" for c in categorical_cols], outputCols=[c+\"_onehot\" for c in categorical_cols])\n",
    "df = encoder.fit(df).transform(df)\n",
    "\n",
    "feature_cols = [\n",
    "    'Age', 'CGPA', 'Stress_Level', 'Depression_Score', 'Anxiety_Score',\n",
    "    'Financial_Stress', 'Semester_Credit_Load'\n",
    "] + [c+\"_idx\" for c in categorical_cols]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features_vec\")\n",
    "df = assembler.transform(df)\n",
    "scaler = StandardScaler(inputCol=\"features_vec\", outputCol=\"features\", withMean=True, withStd=True)\n",
    "scalerModel = scaler.fit(df)\n",
    "df = scalerModel.transform(df)\n",
    "\n",
    "onehot_features = ['Age', 'CGPA', 'Stress_Level', 'Depression_Score', 'Anxiety_Score', 'Financial_Stress', 'Semester_Credit_Load'] + [c+\"_onehot\" for c in categorical_cols]\n",
    "assembler2 = VectorAssembler(inputCols=onehot_features, outputCol=\"features_onehot\")\n",
    "df = assembler2.transform(df)\n",
    "\n",
    "df.select(['Age','CGPA','Stress_Level','Depression_Score','Anxiety_Score','Financial_Stress']).summary().write.csv(f\"{EXPORT_DIR}/eda_summary_stats.csv\", header=True, mode='overwrite')\n",
    "df.withColumn('Depressed', (col('Depression_Score') >= 7).cast('int')).groupBy('Gender').agg(\n",
    "    F.count('*').alias('Total'),\n",
    "    F.sum('Depressed').alias('Depressed_Count'),\n",
    "    (F.sum('Depressed')/F.count('*')).alias('Depression_Rate')\n",
    ").write.csv(f\"{EXPORT_DIR}/eda_gender_vs_depression.csv\", header=True, mode='overwrite')\n",
    "df.groupBy('Sleep_Quality').agg(F.avg('Anxiety_Score').alias('Mean_Anxiety_Score')).write.csv(f\"{EXPORT_DIR}/eda_sleep_quality_anxiety.csv\", header=True, mode='overwrite')\n",
    "df.groupBy('Course').agg(F.avg('Depression_Score').alias('Mean_Depression')).orderBy(F.desc('Mean_Depression')).write.csv(f\"{EXPORT_DIR}/eda_depression_by_course.csv\", header=True, mode='overwrite')\n",
    "df.groupBy('Financial_Stress').agg(F.avg('CGPA').alias('Avg_CGPA')).write.csv(f\"{EXPORT_DIR}/eda_financialstress_vs_cgpa.csv\", header=True, mode='overwrite')\n",
    "\n",
    "na_cols = [F.when(F.col(c).isNull(), 1).otherwise(0).alias(c+'_na') for c in df.columns]\n",
    "na_df = df.select(*na_cols)\n",
    "na_count_df = na_df.select([F.sum(c).alias(c) for c in na_df.columns])\n",
    "na_count_df.write.csv(f\"{EXPORT_DIR}/eda_missing_heatmap.csv\", header=True, mode='overwrite')\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "    num_cols = ['Age', 'CGPA', 'Stress_Level', 'Depression_Score', 'Anxiety_Score', 'Financial_Stress', 'Semester_Credit_Load']\n",
    "    corr_pd = df.select(num_cols).toPandas().corr()\n",
    "    corr_pd.to_csv(f\"{EXPORT_DIR}/eda_correlation_matrix.csv\")\n",
    "    corr_long = pd.melt(corr_pd.reset_index(), id_vars='index')\n",
    "    corr_long.columns = ['Feature1', 'Feature2', 'Correlation']\n",
    "    corr_long.to_csv(f\"{EXPORT_DIR}/eda_correlation_long.csv\", index=False)\n",
    "except:\n",
    "    print(\"Correlation matrix skipped (pandas error or dataset too large).\")\n",
    "\n",
    "for c in ['Gender', 'Sleep_Quality', 'Diet_Quality', 'Relationship_Status', 'Residence_Type']:\n",
    "    df.groupBy(c).count().orderBy(F.desc('count')).write.csv(f\"{EXPORT_DIR}/eda_count_{c}.csv\", header=True, mode='overwrite')\n",
    "\n",
    "kmeans = KMeans(featuresCol='features', k=4, seed=42)\n",
    "kmeans_model = kmeans.fit(df)\n",
    "df = kmeans_model.transform(df)\n",
    "clustering_evaluator = ClusteringEvaluator(featuresCol='features', predictionCol='prediction', metricName='silhouette')\n",
    "silhouette = clustering_evaluator.evaluate(df)\n",
    "print(f\"KMeans Silhouette Score: {silhouette}\")\n",
    "\n",
    "df.groupBy('prediction','Gender','Sleep_Quality','Social_Support').count().write.csv(f\"{EXPORT_DIR}/eda_cluster_profiles.csv\", header=True, mode='overwrite')\n",
    "for feat in ['CGPA','Stress_Level','Depression_Score','Anxiety_Score','Financial_Stress']:\n",
    "    df.groupBy('prediction').agg(F.avg(feat).alias(f'Avg_{feat}')).orderBy('prediction').write.csv(f\"{EXPORT_DIR}/eda_cluster_mean_{feat}.csv\", header=True, mode='overwrite')\n",
    "\n",
    "pca = PCA(k=2, inputCol=\"features\", outputCol=\"pca_features\")\n",
    "pca_model = pca.fit(df)\n",
    "df_pca = pca_model.transform(df)\n",
    "df_pca.select('Age', 'Gender', 'Depression_Score', \n",
    "              F.col('pca_features')[0].alias('PCA1'),\n",
    "              F.col('pca_features')[1].alias('PCA2')).write.csv(\n",
    "                  f\"{EXPORT_DIR}/viz_pca2d.csv\", header=True, mode='overwrite')\n",
    "\n",
    "df.withColumn('Depressed', (col('Depression_Score') >= 7).cast('int'))     .groupBy('Gender', 'Course')     .agg(F.count('*').alias('Total'),\n",
    "         F.sum('Depressed').alias('Depressed_Count'),\n",
    "         (F.sum('Depressed')/F.count('*')).alias('Depression_Rate'))     .write.csv(f\"{EXPORT_DIR}/eda_gender_course_depression.csv\", header=True, mode='overwrite')\n",
    "df.groupBy('Residence_Type', 'Sleep_Quality').agg(\n",
    "    F.avg('Anxiety_Score').alias('Mean_Anxiety_Score')).write.csv(\n",
    "        f\"{EXPORT_DIR}/eda_residence_sleep_anxiety.csv\", header=True, mode='overwrite')\n",
    "if 'prediction' in df.columns:\n",
    "    df.groupBy('prediction','Gender','Relationship_Status').count().write.csv(\n",
    "        f\"{EXPORT_DIR}/viz_cluster_gender_relationship.csv\", header=True, mode='overwrite')\n",
    "\n",
    "if 'prediction' in df.columns:\n",
    "    df = df.drop('prediction')\n",
    "\n",
    "risk_threshold = 7\n",
    "df = df.withColumn(\"High_Depression_Risk\", when(col(\"Depression_Score\") >= risk_threshold, 1).otherwise(0))\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=123)\n",
    "log_reg = LogisticRegression(featuresCol=\"features\", labelCol=\"High_Depression_Risk\", maxIter=20)\n",
    "log_model = log_reg.fit(train_df)\n",
    "preds = log_model.transform(test_df)\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol=\"features_onehot\", labelCol=\"High_Depression_Risk\", numTrees=50)\n",
    "rf_model = rf.fit(train_df)\n",
    "rf_importances = rf_model.featureImportances\n",
    "\n",
    "oh_cols = []\n",
    "for c in onehot_features:\n",
    "    if 'onehot' in c:\n",
    "        try:\n",
    "            n = df.select(c).head()[c].size\n",
    "        except:\n",
    "            n = 0\n",
    "        oh_cols.extend([c+f\"_{i}\" for i in range(n)])\n",
    "    else:\n",
    "        oh_cols.append(c)\n",
    "feature_importance_list = list(zip(oh_cols, rf_importances.toArray()))\n",
    "import pandas as pd\n",
    "pd.DataFrame(feature_importance_list, columns=['Feature','Importance']).to_csv(f\"{EXPORT_DIR}/rf_feature_importances.csv\", index=False)\n",
    "\n",
    "evaluator_roc = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"High_Depression_Risk\", metricName=\"areaUnderROC\")\n",
    "roc_auc = evaluator_roc.evaluate(preds)\n",
    "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"High_Depression_Risk\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator_acc.evaluate(preds)\n",
    "precision = MulticlassClassificationEvaluator(labelCol=\"High_Depression_Risk\", predictionCol=\"prediction\", metricName=\"precisionByLabel\").evaluate(preds)\n",
    "recall = MulticlassClassificationEvaluator(labelCol=\"High_Depression_Risk\", predictionCol=\"prediction\", metricName=\"recallByLabel\").evaluate(preds)\n",
    "f1 = MulticlassClassificationEvaluator(labelCol=\"High_Depression_Risk\", predictionCol=\"prediction\", metricName=\"f1\").evaluate(preds)\n",
    "print(f\"Classification Results - ROC AUC: {roc_auc}, Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1-score: {f1}\")\n",
    "\n",
    "metrics_table = pd.DataFrame([\n",
    "    {'Model': 'Logistic Regression', 'Accuracy': accuracy, 'F1': f1, 'ROC AUC': roc_auc, 'Precision': precision, 'Recall': recall}\n",
    "])\n",
    "metrics_table.to_csv(f\"{EXPORT_DIR}/viz_model_comparison.csv\", index=False)\n",
    "\n",
    "def export_confusion_matrix(preds, export_path):\n",
    "    cm = preds.groupBy('High_Depression_Risk','prediction').count().orderBy('High_Depression_Risk','prediction')\n",
    "    cm.write.csv(export_path, header=True, mode='overwrite')\n",
    "export_confusion_matrix(preds, f\"{EXPORT_DIR}/confusion_matrix.csv\")\n",
    "\n",
    "preds.select('High_Depression_Risk', 'probability', 'prediction').write.csv(\n",
    "    f\"{EXPORT_DIR}/viz_logreg_probabilities.csv\", header=True, mode='overwrite')\n",
    "\n",
    "df_export = df.select(\n",
    "    'Age', 'Gender', 'CGPA', 'Stress_Level', 'Depression_Score', 'Anxiety_Score', 'Sleep_Quality',\n",
    "    'Financial_Stress', 'High_Depression_Risk'\n",
    ")\n",
    "df_export.write.csv(f\"{EXPORT_DIR}/student_mental_health_final_outputs.csv\", header=True, mode='overwrite')\n",
    "\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
